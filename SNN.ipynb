{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTO43HI673Jg7I649a/ReN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TKph/colab/blob/main/SNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GyKGuTdpvG60",
        "outputId": "a4e6cff6-fcb3-43c8-80a2-a9d7e0196147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snntorch\n",
            "  Downloading snntorch-0.9.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/125.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.25.2)\n",
            "Collecting nir (from snntorch)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Collecting nirtorch (from snntorch)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.1.0->snntorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->snntorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nir, nvidia-cusolver-cu12, nirtorch, snntorch\n",
            "Successfully installed nir-1.0.4 nirtorch-1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 snntorch-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "from snntorch import utils\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "b7TiakWhcArN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data**"
      ],
      "metadata": {
        "id": "QgynKFHGcbAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transformの定義\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28,28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "#データの読み込みと前処理\n",
        "data_path='/tmp/data/mnist'\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "dl56Cz1kcHeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1e8426cf-79ea-44c8-b787-be5e74756b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 11515254.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 345912.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3202955.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3144689.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#データローダーの作成\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "HlvE4Io0do8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "1nK1SqLwBnRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28*28\n",
        "hid_dim = 1000\n",
        "out_dim = 10\n",
        "\n",
        "class MySNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_dim, hid_dim)\n",
        "    self.lif1 = snn.Leaky(beta=0.95)\n",
        "    self.fc2 = nn.Linear(hid_dim, out_dim)\n",
        "    self.lif2 = snn.Leaky(beta=0.95)\n",
        "\n",
        "  def forward(self, x): #x.shape = (batch x features), featuresは[0,1]正規化済み\n",
        "    #initialize\n",
        "\n",
        "    mem1 = self.lif1.init_leaky()\n",
        "    mem2 = self.lif2.init_leaky()\n",
        "\n",
        "    spk2_rec = []\n",
        "    mem2_rec = []\n",
        "\n",
        "    for step in range(steps):\n",
        "      cur1 = self.fc1(x) # cur1.shape = (128, 1000)\n",
        "      spk1, mem1 = self.lif1(cur1, mem1)\n",
        "      cur2 = self.fc2(spk1) # cur2.shape = (128, 10)\n",
        "      spk2, mem2 = self.lif2(cur2, mem2) # spk2, mem2.shape = (batch x class) spk2=[0,0,0,0,1,0,0,0,0,1], mem2=[0.2,-0.1,...,0.8]\n",
        "\n",
        "      spk2_rec.append(spk2) # spk2, mem2.shape = (step x batch x class)\n",
        "      mem2_rec.append(mem2)\n",
        "\n",
        "    return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "mysnn = MySNN()"
      ],
      "metadata": {
        "id": "PChJGkfoBmsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics, Loss and Optimizer**"
      ],
      "metadata": {
        "id": "CBq54raeLAnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(data, targets, train=False):\n",
        "    output, _ = mysnn(data.view(batch_size, -1))\n",
        "    _, idx = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "    if train:\n",
        "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mysnn.parameters(), lr=5e-4, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "pcvR2T2ULTWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One iteration training**"
      ],
      "metadata": {
        "id": "3YwJed2SOMLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = 25\n",
        "\n",
        "data, targets = next(iter(train_loader))\n",
        "spk_rec, mem_rec = mysnn(data.view(batch_size, -1))\n",
        "\n",
        "loss_val = torch.zeros((1), dtype=torch.float)\n",
        "\n",
        "for step in range(steps):\n",
        "  loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "loss_val.backward()\n",
        "optimizer.step()\n",
        "\n",
        "spk_rec, mem_rec = mysnn(data.view(batch_size, -1))\n",
        "loss_val = torch.zeros((1), dtype=torch.float)\n",
        "\n",
        "for step in range(steps):\n",
        "  loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "batch_accuracy(data, targets, train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOFJ1nmeOSCr",
        "outputId": "3c41da38-8c45-4317-e709-8f2fd043affc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1000]) torch.Size([128, 10])\n",
            "torch.Size([128, 1000]) torch.Size([128, 10])\n",
            "torch.Size([128, 1000]) torch.Size([128, 10])\n",
            "Train set accuracy for a single minibatch: 8.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "vvptndtKVnR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "steps = 25\n",
        "counter = 0\n",
        "train_loss_hist = []\n",
        "test_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  iter_counter = 0\n",
        "  train_batch = iter(train_loader)\n",
        "\n",
        "  for data, targets in train_batch:\n",
        "    mysnn.train()\n",
        "    #forward\n",
        "    if data.view(batch_size, -1).shape[1] != 784:\n",
        "      print('dataのshapeがおかしい')\n",
        "      break\n",
        "    spk_rec, mem_rec = mysnn(data.view(batch_size, 784))\n",
        "    #loss\n",
        "    loss_train = torch.zeros((1), dtype=torch.float)\n",
        "    for step in range(steps):\n",
        "      loss_train += loss(mem_rec[step], targets)\n",
        "    #update\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    #loss history\n",
        "    train_loss_hist.append(loss_train.item())\n",
        "\n",
        "    #test\n",
        "    with torch.no_grad():\n",
        "      mysnn.eval()\n",
        "      test_data, test_targets = next(iter(test_loader))\n",
        "      #forward\n",
        "      test_spk, test_mem = mysnn(test_data.view(batch_size, -1))\n",
        "      #loss\n",
        "      loss_test = torch.zeros((1), dtype=torch.float)\n",
        "      for step in range(steps):\n",
        "        loss_test += loss(test_mem[step], test_targets)\n",
        "      test_loss_hist.append(loss_test.item())\n",
        "\n",
        "      if counter % 50 == 0:\n",
        "        batch_accuracy(data, targets, train=True)\n",
        "        batch_accuracy(test_data, test_targets, train=False)\n",
        "      counter += 1\n",
        "      iter_counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMzodo0EVov4",
        "outputId": "0fd480da-128c-46ea-c83b-d6a67024c577",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy for a single minibatch: 50.00%\n",
            "Test set accuracy for a single minibatch: 32.03%\n",
            "Train set accuracy for a single minibatch: 89.06%\n",
            "Test set accuracy for a single minibatch: 82.03%\n",
            "Train set accuracy for a single minibatch: 91.41%\n",
            "Test set accuracy for a single minibatch: 85.94%\n",
            "Train set accuracy for a single minibatch: 92.19%\n",
            "Test set accuracy for a single minibatch: 87.50%\n",
            "Train set accuracy for a single minibatch: 92.19%\n",
            "Test set accuracy for a single minibatch: 87.50%\n",
            "Train set accuracy for a single minibatch: 92.19%\n",
            "Test set accuracy for a single minibatch: 90.62%\n",
            "Train set accuracy for a single minibatch: 92.97%\n",
            "Test set accuracy for a single minibatch: 92.19%\n",
            "Train set accuracy for a single minibatch: 90.62%\n",
            "Test set accuracy for a single minibatch: 93.75%\n",
            "Train set accuracy for a single minibatch: 94.53%\n",
            "Test set accuracy for a single minibatch: 90.62%\n",
            "Train set accuracy for a single minibatch: 93.75%\n",
            "Test set accuracy for a single minibatch: 99.22%\n",
            "dataのshapeがおかしい\n"
          ]
        }
      ]
    }
  ]
}