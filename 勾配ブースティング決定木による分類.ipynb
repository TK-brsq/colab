{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5kIYNFa1cx1LZIwSGhLZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TKph/colab/blob/main/%E5%8B%BE%E9%85%8D%E3%83%96%E3%83%BC%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E6%B1%BA%E5%AE%9A%E6%9C%A8%E3%81%AB%E3%82%88%E3%82%8B%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# データの生成\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "g5-77QHt4hh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, ensemble\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aYAFI0gV4mMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sp2vWqAna81"
      },
      "outputs": [],
      "source": [
        "X, y = datasets.make_classification(n_classes=2, n_features=20, n_samples=500, random_state=0)  #2クラス, 特徴量は20個\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 勾配ブースティング決定木の適用\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_xb9UQoq8zfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb = ensemble.GradientBoostingClassifier(n_estimators=500, random_state=0)\n",
        "\n",
        "#比較のためにランダムフォレストも用意する\n",
        "rf = ensemble.RandomForestClassifier(n_estimators=500, random_state=0)\n",
        "\n",
        "gb.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print(f'Gradient Boosting Train score: {gb.score(X_train, y_train)}')\n",
        "print(f'Random Forest Train score: {gb.score(X_train, y_train)}')\n",
        "print(f'Gradient Boosting Train score: {gb.score(X_test, y_test)}')\n",
        "print(f'Random Forest Train score: {gb.score(X_test, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr3NIRNZ86uk",
        "outputId": "a8409bce-8b8d-4ae4-d5e2-5962626eb5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Train score: 1.0\n",
            "Random Forest Train score: 1.0\n",
            "Gradient Boosting Train score: 0.912\n",
            "Random Forest Train score: 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#early stoppingを適用\n",
        "gbes = ensemble.GradientBoostingClassifier(n_estimators=500, validation_fraction=0.25, n_iter_no_change=5, random_state=0)\n",
        "\n",
        "gbes.fit(X_train, y_train)\n",
        "\n",
        "print(f'GB with early stopping Train score: {gbes.score(X_train, y_train)}')\n",
        "print(f'GB with early stopping Test score: {gbes.score(X_test, y_test)}')\n",
        "print(f'the number of estimators: {len(gbes.estimators_)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g68Gu7b_f65",
        "outputId": "adbe9c42-9ef0-47ab-bc19-6baadbe851ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GB with early stopping Train score: 0.9653333333333334\n",
            "GB with early stopping Test score: 0.92\n",
            "the number of estimators: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 解説\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TYpjSEtBnjaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず, 決定木の発展アルゴリズムは他にもAdaBoostやXGBoost, Light GBMなどがある.\n",
        "\n",
        "数式を使った説明はYoutubeに公開されている\"Gradient Boost Part3: Classification\"や\"Introducsion to Boosted Trees\"に譲る.\n",
        "\n",
        "簡単のために2クラス分類とする.\n",
        "\n",
        "\n",
        "1.   分類確率と残差を計算する\n",
        "2.   木を構築する\n",
        "3.   木の葉の予測値を計算する\n",
        "4.   予測値を用いて分類確率と残差を再計算する\n",
        "5.   残差を最小にするような木を構築する\n",
        "6.   繰り返す\n",
        "\n",
        "\n",
        "\n",
        "1.\n",
        "\n",
        "それぞれのデータに対して分類確率を計算する. 最初は $分類確率p_0=\\frac{クラス0番}{データ数}$とする. また, $残差(誤差)e=正解ラベル-分類確率$である. 誤差といえば2乗や絶対値を取るのがよくある操作であるが, このアルゴリズムでは必要ない. 2クラス分類の場合, 正解ラベルは0または1であろう.\n",
        "\n",
        "2.\n",
        "\n",
        "ここの木は何の指標によって構築されるのか分からない\n",
        "\n",
        "3.\n",
        "\n",
        "作成した木のそれぞれの葉(ノード)に対して予測値を計算する. $x$をそのノードに属するデータだとする.\n",
        "$$\n",
        "予測値\\gamma = \\frac{\\sum_X e_x}{\\sum_Xe_xp_x}\n",
        "$$\n",
        "予測値は正しく分類できている葉では正, できていない葉では負になることが多い.\n",
        "\n",
        "4.\n",
        "\n",
        "分類確率を次の式によって更新する.\n",
        "$$\n",
        "p = p_0 + \\eta\\gamma\n",
        "$$\n",
        "正しく分類できているデータの分類確率は大きくなり, できていないデータのそれは小さくなると考えられる.\n",
        "\n",
        "5.\n",
        "\n",
        "2乗和誤差を最小にするように木を構築する.どこの二乗和誤差??"
      ],
      "metadata": {
        "id": "gMZNqz8dnl2j"
      }
    }
  ]
}